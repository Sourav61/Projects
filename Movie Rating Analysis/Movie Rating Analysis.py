# -*- coding: utf-8 -*-
"""Task_5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/Sourav61/Projects/blob/main/Movie%20Rating%20Aanalysis/Movie_Rating_Prediction.ipynb

Author: <a href = "https://github.com/Sourav61">Sourav Pahwa</a>
<br>ID: GO_STP_13420
"""

from google.colab import drive
drive.mount('/content/drive')

"""<b>Assignment/Task 5
Pandas - Data Analysis of IMDB movies data</b>

As we have a basic understanding of the different data structures in Pandas, let’s explore the fun and interesting ‘IMDB-movies-dataset’ and get our hands dirty by performing practical data analysis on real data.

It is an open-source dataset and you can download it from <a href="https://www.kaggle.com/PromptCloudHQ/imdb-data">this link.</a>

We will read the data from the .csv file and perform the following basic operations on movies data

<b>1) Load the IMDb Dataset and read
"""

import pandas as pd
import numpy as np

df = pd.read_csv("IMDB-Movie-Data.csv")

"""<b>2) View the dataset"""

print("The First 10 values of dataset are: \n")
df.head(10)

"""<b>3) Understand some basic information about the dataset and Inspect the dataframe Inspect the dataframe's columns, shapes, variable types etc."""

print("The dataset that we are using consists of: \n\n",df)

print("The shape of the dataset that we are using is: ",df.shape)

print("The size of the dataset that we are using is: ",df.size)

print("The dimension of the dataset that we are using is: ",df.ndim)

print("The length of the dataset that we are using is: ",len(df))

print("The columns present in our dataset that we are using is: \n\n",df.columns)

print("The Columns present in our dataset: \n\n",df.axes)

print("The datatypes of the columns present in our dataset that we are using is: \n\n",df.dtypes)

print("The detailed information about our dataset is: \n \n",df.info)

print("The detailed description of our dataset that we are using is: \n\n",df.describe(include="all"))

print("Let's inspect our data!! \n")
def inspect_data(data):
    return pd.DataFrame({"Data Type":data.dtypes,"No of Levels":data.apply(lambda x: x.nunique(),axis=0), "Levels":data.apply(lambda x: str(x.unique()),axis=0)})
inspect_data(df)

df.head(100).mean()

print("The last 10 values of dataset are: \n")
df.tail(10)

"""<b>4) Data Selection – Indexing and Slicing data"""

mv = df[['Year','Votes','Rating']]
mv

df[['Revenue (Millions)','Runtime (Minutes)']]

df[100:120]

df.iloc[100:120,[1, 6, 7, 8, 9, 10]]

"""<b> 5) Data Selection – Based on Conditional filtering"""

df['Revenue (Millions)']
df_sub = df[df['Revenue (Millions)']>500]
print("All the mentioned movies have been Superhit by generating revenue of more than 500 million!! \n\n")
df_sub

df['Runtime (Minutes)']
df_sub = df[df['Runtime (Minutes)']>175]
df_sub

"""<b> 6) Groupby operations"""

Rev=df.groupby("Title")["Revenue (Millions)"].mean().reset_index()
Rev.sort_values("Revenue (Millions)", ascending=True)

df['Year']
df_sub = df[df['Year']==2016].groupby('Rating')[['Director']].count()
print("Movies produced in 2016 have got the following ratings: \n\n")
df_sub

"""<b> 7) Sorting operation"""

dfsort = df.sort_values(by = 'Runtime (Minutes)')
print(dfsort,"\n The worst movies according to Runtime in Minutes were\n")
print(dfsort.head(2),"\n The best movies that were played alot were: \n")
dfsort.tail(2)

"""<b> 8) Dealing with missing values"""

print(df.isna().any())

print("\n All the columns having True as output are having null values!!")

print(df.isna().sum())

print("\n All the columns having number greater than 0 as output are having null values!!")

"""<b> 9) Dropping columns and null values

<b>There are various methods for dealing with null values like we have dropna method, fillan mehtod etc.We should always use the best considered method i.e. fillna method as dropna method will lead to removal of the dataset and thus will affect accuracy of our model.<b>
"""

df = pd.read_csv("IMDB-Movie-Data.csv")

import missingno as msno

msno.matrix(df.sample(1000))

df1 = df.dropna()

df1

df1.isna().any()

df1.isna().sum()

msno.matrix(df1.sample(800))

"""                                        
                                      OR
"""

df = pd.read_csv("IMDB-Movie-Data.csv")

msno.bar(df.sample(1000))

df1 = df.fillna(0)

df1

df1.isna().sum()

df1.isna().any()

msno.bar(df1.sample(1000))

"""<b>10) Apply( ) functions"""

df1.duplicated().sum()

df1.skew()

df1.kurt()

df1.mean()

df1.median()

df1.max()

df1.min()

df1.mode()